<!-- {"split_candidate": 0, "type": "title", "pages": [0], "bboxes": [[0.26754, 0.14168, 0.74026, 0.18582]]} -->
# VesselVerse: A Dataset and Collaborative Framework for Vessel Annotation

<!-- {"split_candidate": 4, "type": "text", "pages": [0], "bboxes": [[0.42655, 0.2134, 0.5793, 0.22825]]} -->
Anonymized Authors

<!-- {"split_candidate": 4, "type": "text", "pages": [0], "bboxes": [[0.42319, 0.2409, 0.58218, 0.2681]]} -->
Anonymized Affiliations email@anonymized.com

<!-- {"split_candidate": 4, "type": "text", "pages": [0], "bboxes": [[0.26567, 0.29883, 0.74106, 0.52041]]} -->
Abstract. This paper is not about a novel method. Instead, it intro- duces VesselVerse , a large-scale annotation dataset and collaborative framework for brain vessel annotation. It addresses the critical challenge of data annotation availability in supervised learning segmentation and provides a valuable resource for the community. VesselVerse represents the largest public release of brain vessel annotations to date, compris- ing 1,130 annotated images from three public datasets across multiple neurovascular imaging modalities. Its design allows for multi-expert an- notations per image, accounting for variations across diverse annotation protocols. Furthermore, the framework facilitates the inclusion of new annotations and refinements to existing ones, making the dataset dy- namic. To enhance annotation reliability, VesselVerse integrates tools for consensus generation and version control mechanisms, enabling the reversion of errors introduced during annotation refinement. We demon- strate VesselVerse ’s usability by assessing inter-rater agreement among four expert evaluators.

<!-- {"split_candidate": 4, "type": "text", "pages": [0], "bboxes": [[0.26576, 0.53415, 0.73944, 0.56055]]} -->
Keywords: Brain vessel annotation · Multi-expert annotation · Collab- orative framework.

<!-- {"split_candidate": 1, "type": "title", "pages": [0], "bboxes": [[0.21954, 0.58409, 0.37474, 0.60146]]} -->
## 1 Introduction

<!-- {"split_candidate": 4, "type": "text", "pages": [0], "bboxes": [[0.21923, 0.61393, 0.78677, 0.74929]]} -->
Image annotations are essential for developing medical image segmentation algo- rithms. They are critical in training supervised learning models, which typically require a substantial amount of paired image data and segmentation masks. Fur- thermore, even with the increasing use of semi-supervised, weakly supervised, or unsupervised methods, annotations are still needed for validating and evaluating the techniques that have been developed. Although the medical imaging com- munity has made advancements in acquiring and curating large datasets (e.g., [18]), fully annotated data remain scarce, particularly for complex anatomical structures such as the brain’s vasculature.

<!-- {"split_candidate": 4, "type": "text", "pages": [0], "bboxes": [[0.21947, 0.75113, 0.78673, 0.84051]]} -->
The scarcity of large, annotated datasets of brain vessels can be attributed to the intricate and complex nature of the 3D cerebral vasculature. Its highly branched structure, multi-scale representation, and often tortuous paths make manual annotation challenging and time-consuming. Accurately delineating in- dividual vessels, especially smaller ones, requires significant expertise and metic- ulous attention to detail. In addition to the tedious nature of the annotation

<!-- {"split_candidate": 0, "type": "header", "pages": [1], "bboxes": [[0.27563, 0.11711, 0.44666, 0.12832]]} -->
Anonymized Author et al.

<!-- {"split_candidate": 4, "type": "header", "pages": [1], "bboxes": [[0.21924, 0.11751, 0.22904, 0.12665]]} -->
2

<!-- {"split_candidate": 1, "type": "title", "pages": [1], "bboxes": [[0.26622, 0.14441, 0.73914, 0.15774]]} -->
## Table 1. Publicly available brain vessel datasets with annotations (#).

<!-- {"split_candidate": 2, "type": "table", "pages": [1], "bboxes": [[0.21847, 0.1709719147835356, 0.78259, 0.2725844799758449]]} -->
|Dataset|Modalities||#|Annotation Protocol|
|---|---|---|---|---|
|COSTA|TOF-MRA||354|Brain arteries pixel-wise|
|CAS|TOF-MRA||100|Brain arteries pixel-wise|
|IXI from [2]|TOF-MRA||45|Brain arteries pixel-wise|
|SMILE-UHURA|7T TOF-MRA||14|Brain & extraparenchymal vessels pixel-wise|
|TubeTK|MRA||42|Brain arteries centerlines + radius|
|TopCoW23|CTA / TOF-MRA|90|/ 90|Circle of Willis pixel-wise|
|TopCoW24|CTA / TOF-MRA|125|/125|Circle of Willis pixe-wise|

<!-- {"split_candidate": 1, "type": "title", "pages": [1], "bboxes": [[0.21809, 0.53631, 0.7859, 0.56449]]} -->
### Fig. 1. Inter-rater variability in brain vessel annotations. Common labels are high- lighted in yellow, VesselVerse in green, and COSTA [12] in red in TOF-MRA from IXI.

<!-- {"split_candidate": 4, "type": "text", "pages": [1], "bboxes": [[0.21946, 0.59677, 0.78737, 0.70289]]} -->
process, differences in annotation protocols and the subjective interpretation of these protocols further complicate matters. Variations in how vessels are defined, the level of detail required, and the specific tools used can lead to discrepancies in vessel annotation [16], thus introducing inter-rater variability [9]. As a result, comprehensive annotated datasets of the brain vessels are limited, often employ differing annotation protocols (see Table 1) and exhibit significant variations in the resulting annotations (Figure 1).

<!-- {"split_candidate": 4, "type": "text", "pages": [1], "bboxes": [[0.21932, 0.70526, 0.78683, 0.84063]]} -->
Crowdsourcing provides a promising solution for annotating large neurovas- cular imaging datasets while reducing annotator fatigue and errors by sharing the workload among experts. However, recent studies have raised concerns about the annotation quality achieved through crowdsourcing platforms [17]. To fully benefit from crowdsourcing, the complex task of vessel annotation requires qual- ity control mechanisms in place. These should include version control systems for tracking individual contributions, facilitating expert reviews, and consensus mechanisms for harmonizing different annotation styles and resolving discrepan- cies that arise from subjective interpretations of vessel boundaries.

<!-- {"split_candidate": 0, "type": "header", "pages": [2], "bboxes": [[0.23043, 0.11619, 0.78764, 0.12881]]} -->
VesselVerse: A Dataset and Collaborative Framework for Vessel Annotation 3

<!-- {"split_candidate": 4, "type": "text", "pages": [2], "bboxes": [[0.21966, 0.1478, 0.78632, 0.252]]} -->
Although version control systems are widely adopted in software develop- ment, their usage and integration into medical imaging annotated datasets re- main limited. Open-access datasets propose final segmentation masks without tracking the evolution of annotations, and very few previous efforts offer mecha- nisms to integrate multiple expert annotations and refinements [20]. Open-source tools like ITK-Snap [24] or 3D Slicer [10] provide advanced visualization and analysis but lack built-in version-controlled annotation workflows.

<!-- {"split_candidate": 4, "type": "text", "pages": [2], "bboxes": [[0.21952, 0.25373, 0.78704, 0.35776]]} -->
To address these limitations, we introduce VesselVerse , the largest release of brain vessel annotations to date, comprising three publicly available datasets totaling 1,130 annotated images from various neurovascular imaging modalities. VesselVerse also features a novel framework that systematically tracks anno- tation evolution, allows for multiple expert annotations and refinement, and integrates these through consensus generation. The VesselVerse dataset and framework can be accessed at VesselVerseDataset and VesselVerseFramework 1 .

<!-- {"split_candidate": 1, "type": "title", "pages": [2], "bboxes": [[0.21918, 0.38002, 0.39744, 0.39732]]} -->
## 2 Related Works

<!-- {"split_candidate": 4, "type": "text", "pages": [2], "bboxes": [[0.21929, 0.41118, 0.78732, 0.51609]]} -->
Neurovascular Imaging Databases. Large neurovascular imaging datasets like the UK Biobank (over 50,000 images) and OASIS-3 (about 3,000 images) lack annotations. Annotated datasets are much fewer (Table 1), and their dif- fering annotation styles challenge their joint use for model training, something COSTA [12] has addressed partially. VesselVerse offers the largest collection of annotations, with multiple masks that enable users to select from different annotation protocols or create a consensus.

<!-- {"split_candidate": 4, "type": "text", "pages": [2], "bboxes": [[0.21954, 0.51792, 0.7931, 0.62212]]} -->
Crowdsourcing Initiatives. Crowdsourcing platforms have been used for large- scale medical imaging labeling, offering a rapid alternative to expert-driven methods [7,14]. However, studies show that crowd worker quality may be insuffi- cient due to the need for domain expertise and standardized labeling guidelines[17]. VesselVerse implements a version-controlled repository that ensures the trace- ability of expert modifications. Changes of insufficient quality can be rejected, helping to maintain high standards for vessel annotation.

<!-- {"split_candidate": 4, "type": "text", "pages": [2], "bboxes": [[0.21973, 0.62323, 0.78698, 0.74362]]} -->
Annotation platforms and tools. Tools like 3D Slicer [10], ITK-SNAP [24], and MITK offer visualization and annotation capabilities. 3D Slicer extensions leverage deep learning models to enhance manual annotation speed, such as MONAI Label [3], which enables interactive model-based labeling with real-time feedback. However, these frameworks lack version control, do not manage multi- ple annotations, and do not support consensus-based refinement. VesselVerse provides systematic tracking of changes, manages multi-expert annotations, and employs STAPLE-based consensus [21] generation for complete traceability.

<!-- {"split_candidate": 4, "type": "text", "pages": [2], "bboxes": [[0.21951, 0.74411, 0.78628, 0.80351]]} -->
Version Control. VesselVerse is akin to EXACT [11], a collaborative web- based platform for image annotation with version control capabilities. EXACT, however, is 2D-oriented, lacks 3D support and integrated consensus generation, and does not handle the 3D NIFTI format. In contrast, VesselVerse integrates

<!-- {"split_candidate": 4, "type": "footer", "pages": [2], "bboxes": [[0.22445, 0.81229, 0.78664, 0.84049]]} -->
1 A unique link to a central project page with links to the data and code will be provided if accepted. For anonymity purposes, it is not disclosed.

