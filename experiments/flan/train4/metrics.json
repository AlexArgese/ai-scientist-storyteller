{
  "rouge1": 0.0,
  "rouge2": 0.0,
  "rougeL": 0.0,
  "bleu": 0.0,
  "eval_loss": 10.37,
  "notes": "Collapse after 30 epochs on small dataset (~1.8k samples). Likely due to too many epochs, LongT5 not suited, and QLoRA instability. Early stopping not configured correctly, so training ran all 30 epochs."
}
