Setup. A neuroradiologist (E1), a neurologist (E2), a neurosurgery resident (E3), and an expert annotator (E4) from 4 different institutions across 3 different countries were asked to evaluate annotations associated with 20 randomly selected images of VesselVerse . Precisely, five VesselVerse expert annotations were presented to the evaluators in a blinded manner, i.e., the source of each annotation was unknown. Each evaluator was asked to assign a 5 star-based rating to the presented annotations. These ratings reflect their impression of the overall quality of the annotations. Then, evaluators were asked to assign to their bestranked annotation a separate 1â€“5 quality score (where 5 denotes higher quality) guided by anatomical correctness, completeness, and clinical validity. The experiment is repeated twice. In the first experiment, only annotations from models

 VesselVerse: A Dataset and Collaborative Framework for Vessel Annotation 7